# Предсказание оттока клиентов оператора связи


## Описание проекта


Оператор связи `«***»` хочет научиться прогнозировать отток клиентов. Если выяснится, что **пользователь** планирует **уйти**, ему будут **предложены промокоды** и **специальные условия**. Команда оператора собрала персональные данные о некоторых клиентах, информацию об их тарифах и договорах.

То есть **задача проекта** - построение модели машинного обучения с предсказанием оттока клиентов.


`Метрика использования для достижения цели проекта`

Бизнес-метрика здесь — это убытки по двум направлениям: 

* пользователю предложили промокоды, но он не собирался уходить (**false positive**); 
* пользователю ничего не предложили и он ушёл (**false negative**).

*`AUC-ROC`* — метрика, которая учитывает возможность балансировать между **false posititve** и **false negative**.


---

## Стек/инструменты/библиотеки

```python
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.utils import shuffle
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.metrics import roc_curve
from sklearn.metrics import confusion_matrix
from catboost import CatBoostClassifier
from sklearn.linear_model import LogisticRegression
from lightgbm import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier

!pip install phik

import phik
from phik.report import plot_correlation_matrix
```

---

## Итоги исследования

* Были загружены и разобраны данные;
* В ходе предобработки данных создали новый признак **`exited`** (ушедший), который и стал целевым признаком;
* В ходе предобработки данных были также обнаружены пропуски в колонке `TotalCharges`, когда меняли тип данных. Там отсутствовали значения. Все пропуски в общей сумме обнаружены в день выгрузки данных, то есть это прозошло в тот актуальный день, после которого еще не прошло время. Поставили значения с колонки `'monthlycharges'` на месте пропусков, так как цену определнную они уже платят, значит это и составляет их общую сумму;
* Добавили новый признак с днями на контракте кажого клиента **contractdays**. Этот признак поможет модели лучше предсказывать и обучаться;
* Проверили датасет на аномальные значения, создав срез из количественных колонок датафрейма. Создали функцию, которая будет вывела диаграмму размаха и описание данной колонки. С ее помощью посмотрели на **выбросы и аномальные значения**, который **не было обнаружено**;
* В ходе исследовательского анализа обнаружили, что **массовые уходы**  были в **2019** году, начиная с `Октября` по `Декабрь`;
* Посмотрели на кол-во дней клиентов, которые остались, и которые ушли. А также на месячную стоимость, сколько они платили в среднем, сколько максимум/минимум;
* Также сделали визуальную демонстрацию изменения ежемесячной и общей стоимости по годам. Для этого создали функцию **graph**, в которой сгруппировали по решению клиента **exited**, посчитали средние и суммарные функции по ежемесячной и общей стоимости   `monthlycharges`, `totalcharges` по колонке с началом года `begindate`, а затем построили графики по каждому из ниx;
* Создали графическую функцию **statistic_graph**, которая отображает оставшихся и ушедших клиентов и востребованность при этом разных услуг и их влияние на решение клиента. **По ним были сделаны выводы**
* Удалили столбцы с началом действия контракта `begindate` и с расторжением `enddate`, чтобы модель не знала ответы наперед и нормально предсказывала. Также колонку с ID клиента `customerid`. Признак `'seniorcitizen'` имеет тип данных целочисленный, являясь количественным признаком. Для удобства, поменяли значения на строковые yes - 1, no - 0, а потом занесли его в категориальные признаки для кодирования;
* Представили виузально корреляцию всех признаков между собой. Для этого загрузили библиотеку **phik**. Эта библиотека работает со всеми признаками (то есть не только количественными);

* После разделения на выборки, обнаружили на них дисбаланс классов. Если прогнозировали, что клиент НЕ уйдет, то в почти **`74%`** были бы  правы. Но метрика **AUC-ROC** не чувствительна к дисбалансу. Поэтому было принято решение, проводить обучение и предсказывать на обычных выборках с балансировкой классов `class_weight='balanced'`;
* В качестве учебного процесса и только в рамках дополнительного исследования, были сделаны выборки техникой **upsample** и **downsample**;
* Была разработана функция масштабирования **scale** для линейных моделей. Но хоть и не рекомендуется масштабирвоать данные для моделей бустинга и деревьев, также посмотрели и на них значение метрик на масштабированных данных;


* Была разработана функция для кодирования категориальных данных **coder**. Она взяла за основу кодирования `OheHotEncoder` из **sklearn**. Функция использоваласб для всех выборок (обучающая, увеличенная, уменьшенная);

* Также вывели дополнительную метрику точности **accuracy** моделям при помощи атрибута `best_estimator_` и `cross_val_score`;


* Ввели функцию частоты `class_frequency` для подсчета относительных частот. Перевели таблицу в тип `Series`, чтобы смогла `value_counts(normalize=True)` выявить классы. Вывели **матрицу ошибок** `confusion_matrix` для проверки баланса;


* Рассмотрели 4 модели на разных выборках: `CatBoostClassifier`, `LightGBMClassifier`, `LogisticRegression` и `RandomForesClassifier`;

* Лучшей моделью в результате кросс-валидации была выявлена **CatBoostClassifier** с гиперпараметрами: 

`(iterations=850, max_depth=4, learning_rate=0.1, verbose=False, random_state=RANDOM_STATE)`;

* Она и была выбрана для финальной проверки на тестовой выборке;

* Для лучшей модели была построена **roc_curve** (кривую), чтобы посмотреть, как предсказывала она:

* Посмотрели на финальную матрицу ошибок для **CatBoostClassifier** и на важность признаков в обучении и предсказании модели для метрики качества **roc_auc**. По матрице ошибок можно сказать, что модель CatBoostClassifier предсказывает в соотношении клиентов, которые останутся, к клиентам, которые уйдут 3:1. Самих ошибок немного (больше FN ложно-негативных, то есть там, где модель предсказала, что уйдет, а ответ показал, что останется)

* Посмотрели на важность признаков для обучения и предсказывания лучшей модели:
    * По важности признаков видим, что на первом месте кол-во дней на контракте с телекомом **contractdays**. Также большую роль имеет признак ежемясячной траты на услуги **monthycharges**;
    * У модели **CatBoostClassifier** в топе окалася тип `type` оплаты `two year`;
    * Все, что связано с услугами интернета, оказалаись не такими важными признакими для модели
    
* Проверили на адекватность **CatBoostClassifier**, посчитав метрику качества **accuracy** на **cross_val_score**;


* В результате анализа моделей и финального тестирования, **лучше всего по критериям, которые необходимы оператору связи `«***»`, который хочет научиться прогнозировать отток клиентов**, подойдет модель **`CatBoostClassifier`** со значениями: 
  * Метрика качества **AUC-ROC** лучшей модели `0.9366292005207904`
* Отличий от исходного плана не было;
* Трудности в работе не наблюдались, сплошной интерес;
* Все этапы были важны для анализа
