# Восстановление золота из руды



## Описание проекта

В нашем распоряжении данные с параметрами добычи и очистки. В расположении имеем данные в трёх файлах, где собраны:

* обучающая выборка;
* тестовая выборка;
* исходные данные 

Это сырые данные: их просто выгрузили из хранилища. Прежде чем приступить к построению модели, нужно проверить по предоставленной инструкции их на корректность (`внутри проекта описан технологический процесс`).

Данные индексируются датой и временем получения информации (признак date). Соседние по времени параметры часто похожи.

Некоторые параметры недоступны, потому что замеряются и/или рассчитываются значительно позже. Из-за этого в тестовой выборке отсутствуют некоторые признаки, которые могут быть в обучающей. Также в тестовом наборе нет целевых признаков.
Исходный датасет содержит обучающую и тестовую выборки со всеми признаками.

Нужно подготовить прототип модели машинного обучения для `«***»`. Компания разрабатывает решения для эффективной работы промышленных предприятий.

Модель должна предсказать `коэффициент восстановления золота из золотосодержащей руды`.
Модель поможет оптимизировать производство, чтобы не запускать предприятие с убыточными характеристиками.


---

## Стек/инструменты/библиотеки

```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.dummy import DummyRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_error, make_scorer
```

---

## Итоги исследования

* Были загружены и разобраны данные;


* Проверили расчет эффективности обогащения. Значение **MAE** (среднее абсолютное отклонение) оказалось очень мало, что сказало о корректно рассчитанных данных;


* Проанализировали признаки, недоступные в тестовой выборке. Установили, что они напрямую связаны с целевыми признаками. Выходной продукт рассчитывает целевой признак **recovery** на разных этапах. Иными словами они как бы сами целевые признаки, нельзя их интерпретировать как признаки. Устранили эти признаки на обучающей выборке, и добавили целевые признаки в тестовую;


* Были проанализорованы и заполнены пропуски. Заполнение произведено методом `ffill` (соседними значениями), так как близко друг к другу находятся итерации процесса по времени, и следовательно выше вероятность того, что они проходили в похожих условиях и соответственно имели схожие параметры;


* Просмотрели, как меняется концентрация металлов (Au, Ag, Pb) на различных этапах очистки:
   * У всех трех металлов было замечено **увелечение** концентрации **после этапа флотации**;
   * У **золота** наблюдается **скачок вверх** в концентрации с каждым этапом - от примерно **8.1 до 45**;
   * У серебра после флотации характерный рост концентрации. После она падает и в финальном этапе имеет меньшую концентрацию;
   * У **свинца** имеется свойство **усреднения** к концу этапов;
   * Все это, связано с химическим процессом очищения золота, то есть технологическим процессом получения его из смеси
   
   
* Сравнили распределения размеров гранул сырья на обучающей и тестовой выборках. **Не было замечено больших разниц между распределениями на двух этапах очистки для двух выборок**;


* Исследовали суммарные концентрации всех веществ на разных стадиях. Их анализ подтвердил наличие аномальных данных - большое кол-во нулевых значений. **Они были удалены как на обучающей выборке, так и на тестовой**;


* Была введена `функция расчета sMAPE и итоговой sMAPE`;


* С помощью техники **`GridSearchCV()`** и метрики `make_scorer()` были выявлены модели с лучшими гиперпараметрами и лучшей расчетнсотью для них метрики smape, использовав при этом кросс валидацию;


* Было принято решение не масштабировать признаки, так как метрика **sMAPE** одинаково учитывает масштаб и целевого признака, и предсказания;


* Лучшей моделью оказалась модель Случайного Леса **RandomForestRegressor** для двух целевых признаков с одинаково лучшими гиперпараметрами:
  * лучшие гиперпараметры: {`'max_depth'`: 10, `'min_samples_leaf'`: 7, `'min_samples_split'`: 5, `'n_estimators'`: 100};
  * лучшее значение `smape` для **rougher.final.recovery**: **`6.9043`**
  * лучшее значение `smape` для **(final.output.recovery)**: **`9.4406`**
  
* Была пройдена проверка на тестовой выборке и рассчитана итоговая sMAPE:
  * значение `smape` для **rougher.final.recovery** на `тестовой выборке`: **4.476059441596726**;
  * значение `smape` для **(final.output.recovery)** на `тестовой выборке`: **8.004396584166447**
  
  
* **Итоговое sMAPE** - **`7.122312298524016`**;
* **Итоговое значение sMAPE константы** - `9.512005585113844`. Выявленная модель прошла тест на адекватность
